/**<!-------------------------------------------------------------------->
   @file   SurfacePoint.cpp
   @author Travis Fischer (fisch0920@gmail.com)
   @date   Fall 2008
   
   @brief
      Core class representing a single point on the surface of a Shape, 
   which was likely generated by either an intersection with a Ray or random 
   sampling on the surface of the shape.  SurfacePoint encapsulates all of the 
   different information about a surface point and is used for shading 
   evaluation (BSDF), emittance evaluation (Emitter), and so-called importance 
   evaluation (Sensor).
   
      Milton supports the useful distinction between geometric and shading 
   normals defined at a point, where the geometric normal 
   (SurfacePoint::normalG) is the actual normal of the underlying surface at a 
   point, and the shading normal (SurfacePoint::normalS) is a (possibly) 
   perturbed version of the geometric normal.  Shading normals attempt to 
   simulate more complex underlying geometry by varying the apparent normal 
   across the surface of a simpler surface such as a plane. It is important to 
   note that shading normals have no physical basic whatsoever -- they are 
   merely a useful (and very common) method for faking higher resolution (ie. 
   more expensive) geometry. See the bump mapping implementation in Material 
   for an example use of shading normals.
   
   @note
      When finding the closest intersection point between a Ray and a set of 
   objects in the scene, SurfacePoint is used to hold the 'current' closest 
   object and any metadata that shape may need to <b>lazily</b> fill in the 
   rest of the SurfacePoint structure later on (see Shape::initSurfacePoint).
   <!-------------------------------------------------------------------->**/

#include "SurfacePoint.h"
#include <Material.h>
#include <Ray.h>

namespace milton {

SurfacePoint::~SurfacePoint() {
   safeDelete(bsdf);
   
   if (emitter != Material::s_nullEmitter)
      safeDelete(emitter);
   
   if (sensor != Material::s_nullSensor)
      safeDelete(sensor);
}

bool SurfacePoint::init(const Ray &ray, real_t t) {
   ASSERT(ray.direction.isUnit());
   
   if (!Ray::isValid(t))
      return false;
   
   // initialize position
   position = ray.origin + t * ray.direction;
   
   // default to normal aligning with incident vector
   normalG  = -ray.direction;
   
   init();
   bsdf->setWi(ray.direction);
   
   return true;
}

void SurfacePoint::init() {
   ASSERT(shape);
   
   // fill in normalG, uv, and material properties (bsdf, emitter, normalS)
   shape->initSurfacePoint(*this);
   
   ASSERT(bsdf);
   ASSERT(emitter);
   ASSERT(sensor);
   ASSERT(normalG.isUnit());
   ASSERT(normalS.isUnit());
}

std::ostream &operator<<(std::ostream &os, const SurfacePoint &pt) {
   os << "{ " << endl
      << "  shape   = " << pt.shape       << endl
      << "  pos     = " << pt.position    << endl
      << "  normalG = " << pt.normalG     << endl
      << "  normalS = " << pt.normalS     << endl
    //<< "  normalC = " << pt.normalCase  << endl
      << "  index   = " << pt.index       << endl
    //<< "  ior     = " << pt.ior         << endl
      << "  (u,v)   = " << "(" << pt.uv.u << ", " << pt.uv.v << ")" << endl
      << "}";
   
   return os;
}

}

